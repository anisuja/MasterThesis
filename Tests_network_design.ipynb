{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the stages of desiging the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras import optimizers\n",
    "from keras import initializers\n",
    "from keras.layers import Activation, Dense\n",
    "from keras.initializers import glorot_normal, he_normal\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = 'c:/users/Anana/Desktop/Ana/sensores/data/SSST/work_main_complete.csv'\n",
    "# load dataset\n",
    "dataframe = pd.read_csv(file)\n",
    "dataframe = dataframe[['label','HRbias','BRbias','HRbiasV','BRbiasV','deltaHRbias','deltaBRbias', 'neu',  'hap']]\n",
    "dataframe = dataframe.dropna().reset_index(drop=True)\n",
    "dataframe = dataframe.sample(frac=1).reset_index(drop=True)\n",
    "dataset = dataframe.values\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[1:,1:].astype(float)\n",
    "Y = dataset[1:,0]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "target_names = ['calm', 'stress']\n",
    "\n",
    "nTrain=int(0.7*len(X))\n",
    "X_train = X[:nTrain,:]\n",
    "y_train = encoded_Y[:nTrain]\n",
    "X_test = X[nTrain:,:]\n",
    "y_test = encoded_Y[nTrain:]\n",
    "\n",
    "\n",
    "X_std_train = np.nan_to_num(X_train)\n",
    "X_std_test = np.nan_to_num(X_test)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "rescaledX_train = scaler.fit_transform(X_std_train)\n",
    "X_train = StandardScaler().fit_transform(rescaledX_train)\n",
    "rescaledX_test = scaler.fit_transform(X_std_test)\n",
    "X_test = StandardScaler().fit_transform(rescaledX_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neu = ['tanh', 'relu']\n",
    "\n",
    "def create_model(neu):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=8, kernel_initializer='normal', activation=neu))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    optimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "for n in neu:\n",
    "    model = create_model(n)\n",
    "    history = model.fit(X_train, y_train, batch_size=50, epochs=350,\n",
    "          verbose=0, validation_data=(X_test, y_test))\n",
    "\n",
    "    plot_history(history)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "    y_pred = np.empty([len(prediction)], dtype=int)\n",
    "    for i,value in enumerate(prediction):\n",
    "        if value>0.5:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "            \n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=False,\n",
    "                              title='Confusion matrix')\n",
    "    \n",
    "    score_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "    score_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score_test[0],'\\n Test accuracy:', score_test[1])\n",
    "    print('Train loss:', score_train[0],'\\n Train accuracy:', score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wei = ['normal', 'glorot_normal']\n",
    "\n",
    "def create_model(wei):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_dim=8, kernel_initializer=wei, activation='relu'))\n",
    "    #model.add(Dropout(0.3))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1, kernel_initializer=wei, activation='sigmoid'))\n",
    "    optimizer = optimizers.Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "for w in wei:\n",
    "    model = create_model(w)\n",
    "    history = model.fit(X_train, y_train, batch_size=50, epochs=350,\n",
    "          verbose=0, validation_data=(X_test, y_test))\n",
    "\n",
    "    plot_history(history)\n",
    "\n",
    "    prediction = model.predict(X_test)\n",
    "    y_pred = np.empty([len(prediction)], dtype=int)\n",
    "    for i,value in enumerate(prediction):\n",
    "        if value>0.5:\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "            \n",
    "    cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=False,\n",
    "                              title='Confusion matrix')\n",
    "    \n",
    "    score_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "    score_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "    \n",
    "    print('Test loss:', score_test[0],'\\n Test accuracy:', score_test[1])\n",
    "    print('Train loss:', score_train[0],'\\n Train accuracy:', score_train[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neurons and layers\n",
    "\n",
    "- try with/without regularazation and batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#layer = [1,2,3,4,5,6]\n",
    "neurons = [200,250,300,350,400]\n",
    "\n",
    "\n",
    "def create_model(neu):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(neu, input_dim=8, kernel_initializer=he_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(neu, kernel_initializer=he_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(neu, kernel_initializer=he_normal(), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, kernel_initializer=he_normal(), activation='sigmoid'))\n",
    "    optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "scores_n = pd.Dataframe()\n",
    "for l in layers:\n",
    "    for neu in neurons:\n",
    "        model = sequential()\n",
    "        for i in range(0,l):\n",
    "            model.add(Dense(neu, input_dim=8, kernel_initializer=he_normal()))\n",
    "            model.add(BatchNormalization())\n",
    "            model.add(Activation('relu'))\n",
    "            model.add(Dropout(0.3))\n",
    "        optimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "        \n",
    "        print(l,neu)\n",
    "        plot_history(history)\n",
    "\n",
    "        prediction = model.predict(X_test)\n",
    "        y_pred = np.empty([len(prediction)], dtype=int)\n",
    "        for i,value in enumerate(prediction):\n",
    "            if value>0.5:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "                \n",
    "        score_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "        score_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "        col = str(l)+'n'+str(neu)\n",
    "        scores_n[col] = [score_test, score_train]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### learning rate and reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lr = np.random.uniform(low=0.0007, high=0.005, size=(15,))\n",
    "#reg=np.random.uniform(low = 0.3, high= 0.5, size=(5))\n",
    "\n",
    "lr = [0.0009, 0.001, 0.002,0.0025]\n",
    "reg = [0.32,0.33,0.34]\n",
    "\n",
    "def create_model(lr,reg):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(200, input_dim=8, kernel_initializer=he_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(reg))\n",
    "    model.add(Dense(200, kernel_initializer=he_normal()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(reg))\n",
    "    model.add(Dense(200, kernel_initializer=he_normal(), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(reg))\n",
    "    model.add(Dense(1, kernel_initializer=he_normal(), activation='sigmoid'))\n",
    "    optimizer = optimizers.Adam(lr=lr, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "scores=[]\n",
    "for l in lr:\n",
    "    for r in reg:\n",
    "        model = create_model(l, r)\n",
    "        history = model.fit(X_train, y_train, batch_size=50, epochs=350,\n",
    "              verbose=0, validation_data=(X_test, y_test))\n",
    "        \n",
    "        print(l,r)\n",
    "        plot_history(history)\n",
    "    \n",
    "        prediction = model.predict(X_test)\n",
    "        y_pred = np.empty([len(prediction)], dtype=int)\n",
    "        for i,value in enumerate(prediction):\n",
    "            if value>0.5:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "        \n",
    "        score_test = model.evaluate(X_test, y_test, verbose=0)\n",
    "        score_train = model.evaluate(X_train, y_train, verbose=0)\n",
    "        \n",
    "        scores.append([l,r,'Test:',score_test,'Train:',score_train])\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
